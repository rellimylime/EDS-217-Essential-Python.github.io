---
title: "EDS 217 Cheatsheet"
subtitle: "Using pd.read_csv and Its Key Options"
jupyter: eds217_2025
format:
    html:
        toc: true
        toc-depth: 3
        code-fold: show
---

## Basic Usage of pd.read_csv

### Reading a Simple CSV File

```{python}
#| echo: true
import pandas as pd
from io import StringIO

# Create a simple CSV string
csv_data = """
name,age,city
Alice,28,New York
Bob,35,San Francisco
Charlie,42,Chicago
"""

# Read the CSV data
df = pd.read_csv(StringIO(csv_data))
print(df)
```

## Selecting Specific Columns

### Using the `usecols` Parameter

```{python}
#| echo: true
# Read only specific columns
df = pd.read_csv(StringIO(csv_data), usecols=['name', 'city'])
print(df)
```

## Naming Columns

### Using the `names` Parameter

```{python}
#| echo: true
# Rename columns while reading
df = pd.read_csv(StringIO(csv_data), names=['full_name', 'years', 'location'])
print(df)
```

## Specifying an Index

### Using the `index_col` Parameter

```{python}
#| echo: true
# Set 'name' column as index
df = pd.read_csv(StringIO(csv_data), index_col='name')
print(df)
```

## Parsing Dates

### Automatic Date Parsing

```{python}
#| echo: true
csv_data_with_dates = """
date,event
2023-01-15,Conference
2023-02-28,Workshop
2023-03-10,Seminar
"""

df = pd.read_csv(StringIO(csv_data_with_dates), parse_dates=['date'])
print(df.dtypes)
print(df)
```

### Custom Date Parsing

```{python}
#| echo: true
csv_data_custom_dates = """
date,event
15/01/2023,Conference
28/02/2023,Workshop
10/03/2023,Seminar
"""

df = pd.read_csv(StringIO(csv_data_custom_dates), parse_dates=['date'], date_format='%d/%m/%Y')
print(df.dtypes)
print(df)
```

## Handling Headers

### CSV with Multi-line Header

```{python}
#| echo: true
csv_data_with_header = """
# This file contains employee data
# Created by: HR Department, Last updated: 2023-08-23
Employee ID,Name,Department,Salary
101,John Doe,Marketing,50000
102,Jane Smith,Engineering,60000
103,Mike Johnson,Sales,55000
"""

# Read CSV ignoring the first two lines
df = pd.read_csv(StringIO(csv_data_with_header), header=2)
print(df)

# Read CSV treating the first row as header and skipping the next two
df_alt = pd.read_csv(StringIO(csv_data_with_header), header=0, skiprows=2)
print("\nAlternative method:")
print(df_alt)
```

### CSV with No Header

```{python}
#| echo: true
csv_data_no_header = """
Alice,28,New York
Bob,35,San Francisco
Charlie,42,Chicago
"""

df = pd.read_csv(StringIO(csv_data_no_header), header=None, names=['name', 'age', 'city'])
print(df)
```

## Dealing with Missing Data

### Customizing NA Values

```{python}
#| echo: true
csv_data_missing = """
name,age,city
Alice,28,New York
Bob,N/A,San Francisco
Charlie,42,Unknown
"""

df = pd.read_csv(StringIO(csv_data_missing), na_values=['N/A', 'Unknown'])
print(df)
```

## Coercing Columns to Specific Data Types

### Using the `dtype` Parameter

```{python}
#| echo: true
csv_data_types = """
id,name,score
1,Alice,85.5
2,Bob,92.0
3,Charlie,78.5
"""

df = pd.read_csv(StringIO(csv_data_types), dtype={'id': int, 'name': str, 'score': float})
print(df.dtypes)
print(df)
```

## Reading Large CSV Files

### Using `chunksize` for Memory Efficiency

```{python}
#| echo: true
import numpy as np

# Generate a large CSV string (100,000 rows)
np.random.seed(0)
large_csv_data = "id,value\n" + "\n".join([f"{i},{np.random.rand()}" for i in range(100000)])

# Read the large CSV in chunks
chunk_size = 20000
chunks = pd.read_csv(StringIO(large_csv_data), chunksize=chunk_size)

# Process each chunk
for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1}:")
    print(chunk.head())
    print(f"Chunk shape: {chunk.shape}")
    print("\n")
```

Remember, these examples use `StringIO` to simulate reading from a file. When working with actual CSV files, you would replace `StringIO(csv_data)` with the file path or URL.