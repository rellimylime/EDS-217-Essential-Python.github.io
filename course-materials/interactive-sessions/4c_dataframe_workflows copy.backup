---
title: "Interactive Session"
subtitle: "Defining a Comprehensive 9-Step Data Science Workflow"
jupyter: eds217_2025
format: 
    html:
        toc: true
        toc-depth: 3
        code-fold: show
---

## 9-Step Data Science Workflow

**Every data science project follows the same systematic workflow.** Whether you're analyzing Netflix recommendations, climate research, social media trends, or working on your final project, you'll use these 9 steps:

```{mermaid}
flowchart LR
    A["1. Import<br/>ğŸ“‚"] --> B["2. Explore<br/>ğŸ”"] --> C["3. Clean<br/>ğŸ§¹"]
    C --> D["4. Filter<br/>ğŸ¯"] --> E["5. Sort<br/>ğŸ“Š"]
    E --> F["6. Transform<br/>ğŸ”„"] --> G["7. Group<br/>ğŸ‘¥"]
    G --> H["8. Aggregate<br/>ğŸ“ˆ"] --> I["9. Visualize<br/>ğŸ“Š"]

    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#e0f2f1
    style F fill:#fce4ec
    style G fill:#e8eaf6
    style H fill:#f1f8e9
    style I fill:#fff8e1
```

:::{.callout-important title="Why This Workflow Matters"}
**Today**: See all 9 steps in action with ocean temperature analysis  
**Days 4-7**: Master each step individually with detailed sessions  
**Your final project**: Apply this exact workflow to answer your research question!
:::

:::{.callout-tip title="Course Integration"}
Almost all pandas functions and dataframe methods fit into one of these 9 categories. For reference, [here is a cheatsheet](../cheatsheets/workflow_methods.qmd) that maps common pandas functions to our workflow steps.
:::


## Getting Started

Before we begin our interactive session, please follow these steps to set up your Jupyter Notebook:

1. Open JupyterLab and create a new notebook:
   - Click on the `+` button in the top left corner
   - Select `Python 3.11.0` from the Notebook options

2. Rename your notebook:
   - Right-click on the `Untitled.ipynb` tab
   - Select "Rename"
   - Name your notebook with the format: `Session_XY_Topic.ipynb`
     (Replace X with the day number and Y with the session number)

3. Add a title cell:
   - In the first cell of your notebook, change the cell type to "Markdown"
   - Add the following content (replace the placeholders with the actual information):

```markdown
# Day 4: Session C - Dataframe Workflows

[Link to session webpage](https://eds-217-essential-python.github.io/course-materials/interactive-sessions/4c_dataframe_workflows.html)

Date: 09/05/2025

```

4. Add a code cell:
   - Below the title cell, add a new cell
   - Ensure it's set as a "Code" cell
   - This will be where you start writing your Python code for the session

5. Throughout the session:
   - Take notes in Markdown cells
   - Copy or write code in Code cells
   - Run cells to test your code
   - Ask questions if you need clarification

:::{.callout-caution}
Remember to save your work frequently by clicking the save icon or using the keyboard shortcut (Ctrl+S or Cmd+S).
:::

Let's begin our interactive session!

## Ocean Temperature Analysis: Complete Workflow Demo

In this session, we'll systematically work through **every step** of the data science workflow using ocean temperature data. You'll see exactly how professional data scientists approach problems, and by the end, you'll have completed your first full data science project!

**Research Question**: *Which ocean has the warmest average temperatures, and how do temperatures change between seasons?*

Let's systematically work through our 9-step workflow!

## Setting up our environment

First, let's import the libraries we know from previous sessions:

```{python}
#| echo: true

import pandas as pd
import matplotlib.pyplot as plt
```

:::{.callout-note title="Libraries We're Using"}
- **pandas** (`pd`): For working with DataFrames (from Sessions 4a & 4b)
- **matplotlib** (`plt`): For creating charts and graphs (from Session 4c)
:::

## Workflow Progress Tracker

As we work through each step, we'll track our progress through the complete data science workflow:

:::{.callout-note title="Workflow Progress"}
**Ocean Temperature Analysis - Workflow Steps**

â˜ **Step 1: Import** - Load our ocean data  
â˜ **Step 2: Explore** - Discover what we have  
â˜ **Step 3: Clean** - Fix any problems  
â˜ **Step 4: Filter** - Focus on specific data  
â˜ **Step 5: Sort** - Find temperature patterns  
â˜ **Step 6: Transform** - Create new insights  
â˜ **Step 7: Group** - Organize by categories  
â˜ **Step 8: Aggregate** - Calculate summaries  
â˜ **Step 9: Visualize** - Present our results

**Goal**: Complete systematic data science analysis
:::

## ğŸ“‚ Step 1: Import Data

âœ… **Workflow Step 1**: Getting our data into Python

The first step in **every** data science project is getting your data into Python. We'll use `pd.read_csv()` - the same function you learned in Session 4a!

```{python}
#| echo: true

# Step 1: Import our ocean temperature data
df = pd.read_csv('ocean_temperatures_simple.csv')
print("âœ… Step 1 Complete: Data imported successfully!")
print(f"ğŸ“Š Loaded {len(df)} rows of ocean temperature data")
```

:::{.callout-important title="Real Data Science Connection"}
**Professional data scientists** start every project the same way - importing data! Whether it's:
- Climate data from NASA
- User behavior from websites  
- Financial data from banks
- Your final project data

**You always start with**: `pd.read_csv()` or similar import functions
:::

**ğŸ”® Coming Attractions**: Later in the course, you'll learn to import Excel files, JSON data, and even data from databases!

## ğŸ” Step 2: Explore Data

âœ… **Workflow Step 2**: Discovering what we have

Before we can analyze data, we need to **understand** what we're working with. Let's use the exploration methods you learned in Session 4a:

```{python}
#| echo: true

print("ğŸ” EXPLORING OUR OCEAN DATA")
print("=" * 40)

print("\nğŸ“‹ First few rows:")
print(df.head())

print(f"\nğŸ“Š DataFrame info:")
df.info()

print(f"\nğŸ“ˆ Summary statistics:")
print(df.describe())

print("\nâ“ Missing values check:")
print(df.isna().sum())

print("\nâœ… Step 2 Complete: We now understand our data!")
```

:::{.callout-important title="What We Discovered"}
Our ocean dataset contains:
- **5 oceans**: Pacific, Atlantic, Indian, Southern, Arctic
- **Temperature measurements** in degrees Celsius  
- **Salinity measurements** (salt content)
- **Depth measurements** where samples were taken
- **30 total measurements** across different dates

**This is exactly what real data scientists do first!**
:::

**ğŸ”® Coming Attractions**: In Day 5, you'll learn advanced exploration techniques like correlation analysis and custom statistics!

## ğŸ§¹ Step 3: Clean Data

âœ… **Workflow Step 3**: Fixing problems in our data

Good news! Our ocean data is already clean - no missing values to worry about. But let's see what cleaning looks like:

```{python}
#| echo: true

print("ğŸ§¹ CLEANING OUR DATA")
print("=" * 30)

# Check for missing values (we already did this, but let's confirm)
missing_data = df.isna().sum()
print("Missing values per column:")
print(missing_data)

if missing_data.sum() == 0:
    print("\nğŸ‰ Great news! Our data is already clean!")
    df_cleaned = df.copy()  # Make a copy for consistency
else:
    print(f"\nğŸ”§ Cleaning needed...")
    df_cleaned = df.dropna().copy()  # Remove rows with missing values
    print(f"Removed {len(df) - len(df_cleaned)} rows with missing data")

print(f"\nâœ… Step 3 Complete: Clean dataset with {len(df_cleaned)} rows ready for analysis!")
```

:::{.callout-important title="Why Cleaning Matters"}
In real data science projects, you'll spend 50-80% of your time cleaning data! Common problems include:
- **Missing values** (what we just checked for)
- **Duplicate entries**
- **Incorrect data types**
- **Outliers and errors**

**The `.dropna()` method** you just learned will be one of your most-used tools!
:::

**ğŸ”® Coming Attractions**: In Day 5, you'll learn advanced cleaning techniques like handling duplicates and fixing data types!

## ğŸ¯ Step 4: Filter Data

âœ… **Workflow Step 4**: Focusing on what matters for our question

Let's focus on specific data to answer our research question. We'll filter for just the Pacific Ocean to start:

```{python}
#| echo: true

print("ğŸ¯ FILTERING OUR DATA")
print("=" * 30)

# Filter for just Pacific Ocean data (using boolean indexing from Session 4b)
pacific_data = df_cleaned[df_cleaned['location'] == 'Pacific']

print("Pacific Ocean measurements:")
print(pacific_data)
print(f"\nğŸ“Š Found {len(pacific_data)} Pacific Ocean measurements")

# Let's also look at summer data (June measurements)
summer_data = df_cleaned[df_cleaned['date'].str.contains('06-15')]
print(f"\nğŸŒ Summer measurements (June): {len(summer_data)} rows")

print("\nâœ… Step 4 Complete: Focused on specific data for our analysis!")
```

:::{.callout-important title="Filtering in Real Data Science"}
**Professional data scientists** constantly filter data to focus on specific questions:
- Netflix: *"Show me viewing data for comedy movies"*
- Climate research: *"Focus on temperature data from Arctic regions"*  
- Your final project: *"Filter for data relevant to your specific question"*

**The boolean indexing** you just used (`df[df['column'] == value]`) is a fundamental skill!
:::

**ğŸ”® Coming Attractions**: In Day 5, you'll learn complex filtering with multiple conditions using `&` and `|` operators!

## ğŸ“Š Step 5: Sort Data

âœ… **Workflow Step 5**: Organizing data to find patterns

Sorting helps us find the highest and lowest values. Let's find the warmest and coldest ocean measurements:

```{python}
#| echo: true

print("ğŸ“Š SORTING OUR DATA")
print("=" * 30)

# Sort by temperature (warmest first) using .sort_values() from Session 4b
sorted_by_temp = df_cleaned.sort_values('temperature', ascending=False)

print("ğŸ”¥ TOP 5 WARMEST measurements:")
print(sorted_by_temp[['location', 'temperature', 'date']].head())

print("\nğŸ§Š TOP 5 COLDEST measurements:")
print(sorted_by_temp[['location', 'temperature', 'date']].tail())

print("\nâœ… Step 5 Complete: Found temperature patterns by sorting!")
```

:::{.callout-important title="Insights from Sorting"}
**What we discovered**:
- ğŸ”¥ **Warmest**: Atlantic Ocean (27.1Â°C in summer)
- ğŸ§Š **Coldest**: Arctic Ocean (11.5Â°C in winter)
- ğŸ“ˆ **Pattern**: Atlantic and Pacific are warmest, Arctic is coldest

**This is how data scientists find patterns** - sorting reveals extremes and trends!
:::

**ğŸ”® Coming Attractions**: In Day 6, you'll learn to sort by multiple columns and create hierarchical sorting!

## ğŸ”„ Step 6: Transform Data

âœ… **Workflow Step 6**: Creating new insights from existing data

Let's create new information that will help answer our research question:

```{python}
#| echo: true

print("ğŸ”„ TRANSFORMING OUR DATA")
print("=" * 35)

# Create a new column: temperature in Fahrenheit (simple math from Session 4b)
df_cleaned['temperature_f'] = (df_cleaned['temperature'] * 9/5) + 32

# Create a season category based on the date
def get_season(date_str):
    if '01-15' in date_str or '12-15' in date_str:
        return 'Winter'
    elif '06-15' in date_str:
        return 'Summer'
    else:
        return 'Other'

df_cleaned['season'] = df_cleaned['date'].apply(get_season)

# Show our new columns
print("New columns added:")
print(df_cleaned[['location', 'temperature', 'temperature_f', 'season']].head())

print(f"\nğŸ“ˆ Original columns: 5")
print(f"ğŸ“ˆ After transformation: {len(df_cleaned.columns)} columns")
print("\nâœ… Step 6 Complete: Created new insights from our data!")
```

:::{.callout-important title="Why Transform Data?"}
**Transformation creates new insights**:
- ğŸŒ¡ï¸ **Temperature in Fahrenheit**: Makes data accessible to different audiences
- ğŸ—“ï¸ **Season categories**: Helps us compare winter vs summer patterns
- ğŸ“Š **New calculations**: Ratios, categories, derived metrics

**Real data scientists** spend lots of time creating these "feature engineering" transformations!
:::

**ğŸ”® Coming Attractions**: In Day 6, you'll learn advanced transformations and custom functions!


## ğŸ‘¥ Step 7: Group Data

âœ… **Workflow Step 7**: Organizing by categories to find patterns

Now we'll group our data by categories to compare different oceans and seasons:

```{python}
#| echo: true

print("ğŸ‘¥ GROUPING OUR DATA")
print("=" * 30)

# Group by ocean location (using .groupby() from Session 4b)
by_ocean = df_cleaned.groupby('location')

print("ğŸ“Š Number of measurements per ocean:")
print(by_ocean.size())

# Group by season to compare winter vs summer
by_season = df_cleaned.groupby('season')

print("\nğŸ“Š Number of measurements per season:")
print(by_season.size())

print("\nâœ… Step 7 Complete: Data organized by meaningful categories!")
```

:::{.callout-important title="Why Group Data?"}
**Grouping reveals patterns**:
- ğŸŒŠ **By ocean**: Compare Pacific vs Atlantic vs Arctic temperatures
- ğŸ—“ï¸ **By season**: See how temperatures change winter to summer  
- ğŸ“Š **By categories**: Any categorical variable can create groups

**This sets up the next step** - calculating summary statistics for each group!
:::

**ğŸ”® Coming Attractions**: In Day 6, you'll learn to group by multiple columns simultaneously and create complex hierarchical groups!

## ğŸ“ˆ Step 8: Aggregate Data

âœ… **Workflow Step 8**: Calculating summary statistics to answer our question

Now for the exciting part - let's calculate averages to answer "Which ocean is warmest?"

```{python}
#| echo: true

print("ğŸ“ˆ AGGREGATING OUR DATA")
print("=" * 35)

# Calculate average temperature by ocean (using .mean() from Session 4b)
avg_temp_by_ocean = df_cleaned.groupby('location')['temperature'].mean()

print("ğŸŒŠ AVERAGE TEMPERATURE BY OCEAN:")
print(avg_temp_by_ocean.sort_values(ascending=False))

# Calculate average temperature by season
avg_temp_by_season = df_cleaned.groupby('season')['temperature'].mean()

print("\nğŸ—“ï¸ AVERAGE TEMPERATURE BY SEASON:")
print(avg_temp_by_season.sort_values(ascending=False))

# Answer our research question!
warmest_ocean = avg_temp_by_ocean.max()
warmest_ocean_name = avg_temp_by_ocean.idxmax()

print(f"\nğŸ‰ RESEARCH QUESTION ANSWERED!")
print(f"ğŸ† Warmest ocean: {warmest_ocean_name} ({warmest_ocean:.1f}Â°C)")

print("\nâœ… Step 8 Complete: Found the answer through aggregation!")
```

:::{.callout-important title="Key Discovery!"}
**Our Research Results**:
- ğŸ¥‡ **Warmest Ocean**: Atlantic (24.1Â°C average)
- ğŸ¥ˆ **Second Warmest**: Pacific (20.7Â°C average)  
- ğŸ¥‰ **Coldest**: Arctic (12.9Â°C average)
- ğŸŒ **Summer is warmer** than winter (as expected!)

**This is exactly how real data science works** - use aggregation to answer research questions!
:::

**ğŸ”® Coming Attractions**: In Day 6, you'll learn advanced aggregation functions like `.agg()` to calculate multiple statistics at once!

## ğŸ“Š Step 9: Visualize Data

âœ… **Workflow Step 9**: Telling our story with charts

The final step is creating a chart to communicate our findings clearly:

```{python}
#| echo: true

print("ğŸ“Š VISUALIZING OUR RESULTS")
print("=" * 35)

# Create average temperature data for plotting
avg_temps = df_cleaned.groupby('location')['temperature'].mean().sort_values(ascending=False)

# Create a bar chart (using matplotlib from Session 4c)
plt.figure(figsize=(10, 6))
avg_temps.plot(kind='bar', color=['red', 'orange', 'blue', 'green', 'purple'])
plt.title('ğŸŒŠ Average Ocean Temperatures: Research Results', fontsize=16, fontweight='bold')
plt.xlabel('Ocean Location', fontsize=12)
plt.ylabel('Average Temperature (Â°C)', fontsize=12)
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()

# Add our research conclusion to the plot
plt.figtext(0.5, 0.02, 'ğŸ† Research Conclusion: Atlantic Ocean is the warmest on average!', 
            ha='center', fontsize=12, fontweight='bold')

plt.show()

print("\nâœ… Step 9 Complete: Story told through visualization!")
```

:::{.callout-important title="ğŸ‰ CONGRATULATIONS! ğŸ‰"}
**You just completed your first full data science project!**

**ğŸŒŠ Research Question**: *Which ocean has the warmest average temperatures?*  
**ğŸ“Š Answer**: **Atlantic Ocean** (24.1Â°C average)  
**ğŸ† Method**: Complete 9-step data science workflow!

**You've completed the full workflow - you're officially a data scientist!** ğŸ“
:::

## ğŸ¯ What You Accomplished Today

### **âœ… Complete Workflow Mastery**
You just used the **exact same process** that professional data scientists use every day:

1. âœ… **Imported** real ocean temperature data
2. âœ… **Explored** to understand what you had  
3. âœ… **Cleaned** (lucky us - data was already clean!)
4. âœ… **Filtered** to focus on specific questions
5. âœ… **Sorted** to find temperature patterns
6. âœ… **Transformed** data to create new insights  
7. âœ… **Grouped** by meaningful categories
8. âœ… **Aggregated** to calculate summary statistics
9. âœ… **Visualized** results with a professional chart

### **ğŸ”® Your Data Science Journey Continues**

**Next Week - Individual Step Mastery**:
- **Day 5**: Advanced filtering and transformation techniques
- **Day 6**: Complex grouping and aggregation methods  
- **Day 7**: Professional data visualization with seaborn

**Your Final Project**: Use this **exact 9-step workflow** to answer your own research question!

### **ğŸ”„ The Workflow You Can Always Apply**

Whenever you encounter a new dataset or research question, systematically work through these 9 steps:
1. Import â†’ 2. Explore â†’ 3. Clean â†’ 4. Filter â†’ 5. Sort â†’ 6. Transform â†’ 7. Group â†’ 8. Aggregate â†’ 9. Visualize

**This is your systematic approach to data science success!** ğŸ¯

::: {.center-text .body-text-xl .teal-text}
ğŸ‰ End interactive session 4C - You're now a data scientist! ğŸ‰
:::