---
title: "Day 1: Tasks & activities (DRAFT)"
subtitle: "ğŸ¬ Preview: Your Data Science Future!"
execute:
  echo: false
  include: false
python: eds217_2025
format: 
    html:
        toc: true
        toc-depth: 3
        code-fold: show
---

::: {style="width: 80%; margin: auto;"}
![](https://media.arcus.org/files/styles/juicebox_medium/public/ima/images/Martinez_IMG_4771.jpg?itok=V5IY36X3)
:::

:::{.gray-text .center-text}
*Toolik from the boardwalk* (source)[https://media.arcus.org/album/polartrec-2019-alejandra-martinez/30679]
:::

## ğŸ¯ **Welcome to Your Data Science Future!**

**Today's Mission:** Get a sneak peek at where you're headed! You'll copy and run Python code to see what's possible with data science. Think of this as a movie trailer for the skills you'll build over the next week.

### ğŸ¬ **"Coming Attractions" Approach**
- **Your job:** Copy, paste, and run the code exactly as written
- **Our job:** Show you what's happening (not how it works yet!)
- **The goal:** Get excited about what you'll learn and see the big picture

:::{.callout-important title="Don't Panic! ğŸš€"}
You're not expected to understand every line of code today. By next Friday, you'll know exactly how all of this works. For now, just enjoy the ride and see what's possible!
:::

## ğŸ—“ï¸ **When You'll Master These Skills**

| What you'll see today | When you'll learn it | What we'll cover |
|----------------------|---------------------|------------------|
| `import pandas as pd` | Day 3-4 | Data structures and DataFrames |
| `pd.read_csv()` | Day 4 | Loading data from files |
| `df.head()`, `df.info()` | Day 4 | Data exploration methods |
| `df.groupby()` | Day 6 | Data aggregation and grouping |
| `plt.plot()`, `plt.bar()` | Day 7 | Data visualization |

## Background and Data Source

Our data comes from the [Arctic Long Term Ecological Research](https://arc-lter.ecosystems.mbl.edu) station. The Arctic Long Term Ecological Research (ARC LTER) site is part of a network of sites established by the National Science Foundation to support long-term ecological research in the United States. The research site is located in the foothills region of the Brooks Range, North Slope of Alaska (68Â° 38'N, 149Â° 36.4'W, elevation 720 m). 

The Arctic LTER project's goal is to understand and predict the effects of environmental change on arctic landscapes, both natural and anthropogenic. Researchers at the site use long-term monitoring and surveys of natural variation of ecosystem characteristics, experimental manipulation of ecosystems (years to decades) and modeling at ecosystem and watershed scales to gain an understanding of the controls of ecosystem structure and function. The data and insights gained are provided to federal, Alaska state and North Slope Borough officials who regulate the lands on the North Slope and through this web site.

We will be using some basic weather data downloaded from Toolik Station: 

- Toolik Station Meteorological Data: toolik_weather.csv Shaver, G. 2019. A multi-year DAILY weather file for the Toolik Field Station at Toolik Lake, AK starting 1988 to present. ver 4. Environmental Data Initiative. https://doi.org/10.6073/pasta/ce0f300cdf87ec002909012abefd9c5c (Accessed 2021-08-08).

I have already downloaded this data and placed in our course repository, where we can access it easily using its GitHub raw URL. 

Let's dive into your preview of data science with Python!

---

## Instructions

### ğŸš€ **Step 1: Import the Magic Tools**

First, we'll import the libraries that make data science possible in Python.

**ğŸ¬ Copy and paste this code:**

```python
import pandas as pd
import matplotlib.pyplot as plt
```

```{python}
#| echo: false
#| include: false
import pandas as pd
import matplotlib.pyplot as plt
```

ğŸ­ **What just happened?** 
We imported two powerful libraries! `pandas` is like Excel but supercharged for data analysis, and `matplotlib` creates beautiful(ish) plots. 
**ğŸ“ Coming up:** You'll learn about Python imports and libraries on Days 2-3.

---

### ğŸš€ **Step 2: Load Real Climate Data**

Now we'll load 15,000+ rows of Arctic weather data in just one line!

Our data is located at: 
`https://raw.githubusercontent.com/environmental-data-science/eds217-day0-comp/main/data/raw_data/toolik_weather.csv`

**ğŸ¬ Copy and paste this code:**

```python
url = 'https://raw.githubusercontent.com/environmental-data-science/eds217-day0-comp/main/data/raw_data/toolik_weather.csv'
df = pd.read_csv(url)
```

```{python}
#| echo: false
#| include: false
url = 'https://raw.githubusercontent.com/environmental-data-science/eds217-day0-comp/main/data/raw_data/toolik_weather.csv'
df = pd.read_csv(url)
```

ğŸ­ **What just happened?** 
We loaded over 15,000 rows of climate data from the internet in one line! The data is now stored in a "DataFrame" called `df`.
**ğŸ“ Coming up:** Day 4 will teach you all about loading and working with data files.

:::{.callout-tip title="R vs Python: Data Loading"}
This is just like `df <- read.csv(url)` in R! Both pandas DataFrames and R data.frames are tabular data structures. The main syntax difference is Python's dot notation: `pd.read_csv()` vs R's `read.csv()`. Both can read directly from URLs, which is incredibly convenient for reproducible research!
:::

---

### ğŸš€ **Step 3: Peek at the Data**

Let's see what our Arctic climate data looks like!

**ğŸ¬ Copy and paste this code:**

```python
df.head()
```

```{python}
#| echo: false
#| include: false
df.head()
```

ğŸ­ **What just happened?** 
We previewed the first 5 rows of our 15,000+ row dataset! You can see daily weather measurements from Alaska.
**ğŸ“ Coming up:** Day 4 morning will teach you data exploration methods like this.

:::{.callout-tip title="R vs Python: Data Exploration"}
This is exactly like `head(df)` in R! The key difference is Python's object-oriented approach: `df.head()` vs R's functional approach `head(df)`. Both show you the first few rows, but Python treats the DataFrame as an object that has methods (like `.head()`) built into it.
:::

---

### ğŸš€ **Step 4: Check Data Quality**

Real data science involves checking for missing or problematic data.

**ğŸ¬ Copy and paste this code:**

```python
df.isnull().sum()
```

```{python}
#| echo: false
#| include: false
df.isnull().sum()
```

ğŸ­ **What just happened?** 
We checked every column for missing data! Looks like our temperature data is complete (0 missing values), which is great.
**ğŸ“ Coming up:** Day 5 will teach you all about data cleaning and handling missing values.

:::{.callout-tip title="R vs Python: Missing Data Check"}
In R, you'd use `sum(is.na(df))` to count missing values. Python uses `df.isnull().sum()` - notice the chaining of methods! This reads left-to-right: "take the DataFrame, check for null values, then sum them up." Both approaches give you the count of missing values per column.
:::

---

### ğŸš€ **Step 5: Get Data Summary Statistics**

Let's get a statistical overview of our climate data.

**ğŸ¬ Copy and paste this code:**

```python
df.describe()
df.info()
```

```{python}
#| echo: false
#| include: false
df.describe()
df.info()
```

ğŸ­ **What just happened?** 
We got instant statistics and information about our entire dataset! You can see temperature ranges, averages, and data types.
**ğŸ“ Coming up:** Day 4 will teach you how to explore and understand your datasets.

:::{.callout-tip title="R vs Python: Data Summary"}
These are like `summary(df)` and `str(df)` in R. Python's `.describe()` gives you the statistical summary (like `summary()`) while `.info()` shows the structure (like `str()`). Notice how Python uses dot notation - the DataFrame object has these methods built in, whereas R uses separate functions that take the data frame as input.
:::

---

### ğŸš€ **Step 6: Calculate Monthly Averages**

Now for some real data analysis - let's find average temperatures by month!

**ğŸ¬ Copy and paste this code:**

```python
monthly = df.groupby('Month')
monthly_means = monthly['Daily_AirTemp_Mean_C'].mean()
```

```{python}
#| echo: false
#| include: false
monthly = df.groupby('Month')
monthly_means = monthly['Daily_AirTemp_Mean_C'].mean()
```

ğŸ­ **What just happened?** 
We grouped 15,000+ daily temperature readings by month and calculated averages! This turned years of daily data into 12 monthly summaries.
**ğŸ“ Coming up:** Day 6 will teach you all about grouping and aggregating data like this.

:::{.callout-tip title="R vs Python: Data Grouping"}
This is exactly like using `df %>% group_by(Month) %>% summarize(mean_temp = mean(Daily_AirTemp_Mean_C))` in dplyr! Both approaches group data and calculate statistics. Python's syntax is `df.groupby('column')['target_column'].function()`, while R uses the pipe operator `%>%` to chain operations. Both are powerful for data aggregation!
:::

---

### ğŸš€ **Step 7: Create Your First Visualization**

Time to turn numbers into pictures! Let's plot the monthly temperature patterns.

**ğŸ¬ Copy and paste this code:**

```python
plt.plot(monthly_means)
```

```{python}
#| echo: false
#| include: false
plt.plot(monthly_means)
```

**Now let's make it even better with labels:**

```python
months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
plt.bar(months, monthly_means)
```

```{python}
#| echo: false
#| include: false
months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
plt.bar(months, monthly_means)
```

ğŸ­ **What just happened?** 
You created professional data visualizations! The bar chart clearly shows Alaska's extreme seasonal temperature differences.
**ğŸ“ Coming up:** Day 7 will teach you how to create amazing visualizations and customize them.

:::{.callout-tip title="R vs Python: Data Visualization"}
This is like creating plots with `ggplot(df, aes(x=Month, y=temp)) + geom_bar()` in R! Python's matplotlib uses a more direct approach: `plt.plot()` and `plt.bar()` create plots immediately. Both are powerful - ggplot2 uses a "grammar of graphics" approach while matplotlib is more imperative. You'll learn both have their strengths!
:::

---

### ğŸš€ **Step 8: Analyze Climate Trends Over Time**

Let's explore how temperatures have changed over the decades!

**ğŸ¬ Copy and paste this code:**

```python
year = df.groupby('Year')
yearly_means = year['Daily_AirTemp_Mean_C'].mean()
plt.plot(yearly_means)
```

```{python}
#| echo: false
#| include: false
year = df.groupby('Year')
yearly_means = year['Daily_AirTemp_Mean_C'].mean()
plt.plot(yearly_means)
```

**And as a bar chart:**

```python
year_list = df['Year'].unique()
plt.bar(year_list, yearly_means)
```

```{python}
#| echo: false
#| include: false
year_list = df['Year'].unique()
plt.bar(year_list, yearly_means)
```

ğŸ­ **What just happened?** 
You analyzed climate trends across multiple decades! You can see how Arctic temperatures have varied over time - real climate science!
**ğŸ“ Coming up:** This combines Day 6 skills (grouping data) with Day 7 skills (visualization).

:::{.callout-tip title="R vs Python: Time Series Analysis"}
This is just like grouping by year in R and plotting the results! Whether you use `df %>% group_by(Year) %>% summarize()` in R or `df.groupby('Year').mean()` in Python, you're doing the same analytical thinking. The syntax differs, but the data science concepts are identical.
:::

---

### ğŸš€ **Step 9: Save Your Work**

Data scientists always save their analyses for future use.

**ğŸ¬ Copy and paste this code:**

```python
monthly_means.to_csv("monthly_means.csv", header=True)
```

```{python}
#| echo: false
#| include: false
monthly_means.to_csv("monthly_means.csv", header=True)
```

ğŸ­ **What just happened?** 
You saved your analysis results to a file that you (or other scientists) can use later! This is how research becomes reproducible.
**ğŸ“ Coming up:** Day 4 will teach you all about importing, exporting, and managing data files.

:::{.callout-tip title="R vs Python: Data Export"}
This is just like `write.csv(monthly_means, "monthly_means.csv")` in R! Python uses the object-oriented approach where the data (your Series `monthly_means`) has a method `.to_csv()` built into it. R uses a function that takes the data as input. Both create the exact same CSV file - just different syntax approaches to the same goal.
:::

---

## ğŸ‰ **Congratulations! You're a Data Scientist!**

You just completed a real data science workflow:
- âœ… Loaded real climate data from the internet
- âœ… Explored and understood your dataset  
- âœ… Calculated meaningful statistics
- âœ… Created professional visualizations
- âœ… Analyzed climate trends over time
- âœ… Saved your results for future use

### ğŸ§  **What You've Seen Today**

This preview showed you the **power and simplicity** of Python for data science. In just a few lines of code, you:
- Processed 15,000+ rows of climate data
- Created multiple visualizations
- Performed real climate analysis
- Saved reproducible results

### ğŸš€ **What's Next**

Over the next week, you'll learn **exactly how each line works**:
- **Days 2-3:** Python fundamentals (variables, data types, control flows) - the building blocks
- **Day 4:** DataFrames and data loading (like today's `pd.read_csv()`) - working with structured data
- **Day 5:** Data cleaning and manipulation - making messy data analysis-ready
- **Day 6:** Grouping and aggregation (like today's `groupby()`) - summarizing and analyzing patterns
- **Day 7:** Data visualization (like today's plots) - creating publication-quality graphics

By Friday, you'll understand every single line of code you ran today - and you'll be able to write it all yourself!

### ğŸ”„ **R Skills Transfer**

Your R experience gives you a huge advantage! You already understand:
- **Data structures** (data.frames â†” DataFrames)
- **Statistical thinking** (same concepts, different syntax)
- **Data workflows** (load â†’ explore â†’ analyze â†’ visualize)
- **Reproducible research** (scripts and documentation)

Python will feel familiar because the **thinking** is the same - you're just learning new **syntax** for concepts you already know!

## ğŸ¤” **Reflection Questions**

Take a moment to think about:
1. What surprised you most about what Python can do with data?
2. Which part of the analysis was most interesting to you?
3. What questions do you have about how this all works?
4. How might you use these skills in your future research or work?

**Add your thoughts in a new markdown cell below!**

---

:::{.callout-note title="Remember"}
Today was about inspiration and seeing possibilities. Don't worry if you don't understand everything yet - that's exactly what the rest of the course is for! You're going to do amazing things with data science. ğŸš€
:::

::: {.center-text .body-text-xl .teal-text}
End Activity Session (Day 1) - Welcome to Your Data Science Journey! 
::: 